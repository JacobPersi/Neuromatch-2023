{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run \"./0. Download HCP Task Dataset.ipynb\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "execution": {},
    "id": "zN_neRXA49Xq"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "execution": {},
    "id": "HxFfdj7y49Xr"
   },
   "outputs": [],
   "source": [
    "HCP_DIR = \"./hcp_task\"\n",
    "\n",
    "TIME_RESOLUTION = 0.72  # fMRI time resolution, in seconds.\n",
    "\n",
    "# These could be read from file, but they're constants so lets treat them as such:\n",
    "DATA_LENGTH = 176\n",
    "DURATION = 18.0\n",
    "\n",
    "NORMALIZE_DATA = True\n",
    "OFFSET = 5 # Offset each condition by this to account for BOLD signal delay. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "subjects = np.loadtxt(os.path.join(HCP_DIR, 'subjects_list.txt'), dtype='str')\n",
    "regions = np.load(f\"{HCP_DIR}/regions.npy\").T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper functions.\n",
    "def scale_array(arr):\n",
    "    min_val = np.min(arr)\n",
    "    max_val = np.max(arr)\n",
    "    scaled_arr = 2 * ((arr - min_val) / (max_val - min_val)) - 1\n",
    "    return scaled_arr\n",
    "\n",
    "def load_timeseries(file_path, return_region_dict = False, normalize_data = False):\n",
    "    ts = np.load(file_path)\n",
    "\n",
    "    ts -= ts.mean(axis=1, keepdims=True)\n",
    "    #ts /= ts.std(axis=1, keepdims=True)\n",
    "    \n",
    "    if (normalize_data):\n",
    "        for index, array in enumerate(ts):\n",
    "            ts[index] = scale_array(array)\n",
    "        \n",
    "    #ts = preprocessing.normalize(ts)\n",
    "    #ts = preprocessing.scale(ts)\n",
    "\n",
    "    if (return_region_dict):\n",
    "        return_dict = {}\n",
    "        for i in range(len(regions[0])):\n",
    "            return_dict[regions[0][i]] = ts[i]\n",
    "        return return_dict\n",
    "    \n",
    "    return ts\n",
    "\n",
    "def load_evs(ev_directory):\n",
    "    neut = np.loadtxt(f\"{ev_directory}/neut.txt\", ndmin=2, unpack=True)\n",
    "    neut_onset = neut[0]\n",
    "\n",
    "    fear = np.loadtxt(f\"{ev_directory}/fear.txt\", ndmin=2, unpack=True)\n",
    "    fear_onset = fear[0]\n",
    "\n",
    "    # Combine the neut_onset and fear_onset into an array and sort it by onset. \n",
    "    combined = [(\"Neut\", onset) for onset in neut_onset] + [(\"Fear\", onset) for onset in fear_onset]\n",
    "    _sorted = sorted(combined, key=lambda x: x[1])\n",
    "\n",
    "    return_array = []\n",
    "    for condition, onset in _sorted:\n",
    "        \n",
    "        # Use onset and duration to index into the data array. \n",
    "        start_frame = np.floor(onset / TIME_RESOLUTION).astype(int)\n",
    "        end_frame = start_frame + np.ceil(DURATION / TIME_RESOLUTION).astype(int)\n",
    "\n",
    "        # Add our bold-signal delay offset.\n",
    "        start_frame = start_frame + OFFSET\n",
    "        end_frame = end_frame + OFFSET\n",
    "\n",
    "        # The last three trials of the last block were not recorded, so we truncate this block to prevent index out of range.  \n",
    "        if (end_frame >= DATA_LENGTH):\n",
    "            end_frame = DATA_LENGTH\n",
    "\n",
    "        return_array.append({\n",
    "            \"Condition\": condition,\n",
    "            \"Onset\": onset,\n",
    "            \"Duration\": DURATION,\n",
    "            \"Frames\": (start_frame, end_frame)\n",
    "        })\n",
    "\n",
    "    return return_array\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "execution": {},
    "id": "0Yjf5UQM49Xt"
   },
   "outputs": [],
   "source": [
    "# Create full data structure. \n",
    "manifest = {}\n",
    "for subject_id in subjects:\n",
    "     \n",
    "    if subject_id not in manifest:\n",
    "        manifest[subject_id] = []\n",
    "            \n",
    "    for trial_index, trial in enumerate([\"LR\", \"RL\"]):\n",
    "        data_path = f\"{HCP_DIR}/subjects/{subject_id}/EMOTION/tfMRI_EMOTION_{trial}/data.npy\"\n",
    "        ev_path = f\"{HCP_DIR}/subjects/{subject_id}/EMOTION/tfMRI_EMOTION_{trial}/EVs\"\n",
    "\n",
    "        time_series = load_timeseries(data_path, normalize_data=NORMALIZE_DATA)\n",
    "        region_time_series = load_timeseries(data_path, return_region_dict=True, normalize_data=NORMALIZE_DATA)\n",
    "        condition_data = load_evs(ev_path)\n",
    "\n",
    "        manifest[subject_id].append({\n",
    "            \"data\": time_series,\n",
    "            \"region_data\": region_time_series,\n",
    "            \"condition_spans\": condition_data\n",
    "        })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X: (800, 360, 25)\n",
      "Y: (800,)\n"
     ]
    }
   ],
   "source": [
    "# Prepare the data for modeling:\n",
    "X = []\n",
    "Y = []\n",
    "\n",
    "for subject_index, subject_id in enumerate(subjects):\n",
    "    for trial_index, trial in enumerate(manifest[subject_id]):\n",
    "        for block_index, condition_dict in enumerate(trial[\"condition_spans\"]): \n",
    "\n",
    "            # To ensure data balance, we drop the last block of each condition... \n",
    "            # Todo: Find a more sophisticated approach to handling the data imbalance.  \n",
    "            if (block_index+1 == 5 or block_index+1 == 6):\n",
    "                break\n",
    "\n",
    "            start_index = condition_dict['Frames'][0]\n",
    "            end_index = condition_dict['Frames'][1]\n",
    "            \n",
    "            x = trial[\"data\"][:, start_index : end_index]\n",
    "            y = 0 if condition_dict['Condition'] == \"Neut\" else 1\n",
    "\n",
    "            X.append(x)\n",
    "            Y.append(y)\n",
    "\n",
    "X = np.array(X)\n",
    "Y = np.array(Y)\n",
    "\n",
    "print(f\"X: {X.shape}\")\n",
    "print(f\"Y: {Y.shape}\")"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "load_hcp_task_with_behaviour",
   "provenance": [],
   "toc_visible": true
  },
  "kernel": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
